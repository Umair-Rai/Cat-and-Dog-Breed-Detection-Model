{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "fTnHZAYx723o",
        "outputId": "ca61262f-4149-4696-f111-567c7f6dc2a1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-26c57d49-6c88-4c0d-af6d-92b7a23c0d2a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-26c57d49-6c88-4c0d-af6d-92b7a23c0d2a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"racist20\",\"key\":\"77ac2b78e1fddb50f02a36e819b11815\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle competitions download -c petfinder-adoption-prediction\n",
        "!unzip -q petfinder-adoption-prediction.zip -d /content/petfinder_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmd1AmNd757l",
        "outputId": "7f9f5fec-9f3f-433e-ecb8-0da388886bb3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading petfinder-adoption-prediction.zip to /content\n",
            " 97% 1.88G/1.94G [00:01<00:00, 1.15GB/s]\n",
            "100% 1.94G/1.94G [00:01<00:00, 1.15GB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar -O /content/stanford_images.tar\n",
        "!mkdir -p /content/stanford_dogs\n",
        "!tar -xf /content/stanford_images.tar -C /content/stanford_dogs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iqqD3FF7-D3",
        "outputId": "c50468ac-2fdd-43f5-ac82-e3c9581e42ed"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-19 15:10:49--  http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar\n",
            "Resolving vision.stanford.edu (vision.stanford.edu)... 171.64.68.10\n",
            "Connecting to vision.stanford.edu (vision.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 793579520 (757M) [application/x-tar]\n",
            "Saving to: ‚Äò/content/stanford_images.tar‚Äô\n",
            "\n",
            "/content/stanford_i 100%[===================>] 756.82M  61.5MB/s    in 16s     \n",
            "\n",
            "2025-05-19 15:11:05 (48.6 MB/s) - ‚Äò/content/stanford_images.tar‚Äô saved [793579520/793579520]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q http://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\n",
        "!wget -q http://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz\n",
        "\n",
        "!mkdir /content/oxford_pet_data\n",
        "!tar -xzf images.tar.gz -C /content/oxford_pet_data\n",
        "!tar -xzf annotations.tar.gz -C /content/oxford_pet_data"
      ],
      "metadata": {
        "id": "O7s4lkIv7_k1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, shutil\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "6PGkWFAx8BM_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load breed labels from PetFinder\n",
        "breed_labels = pd.read_csv(\"/content/petfinder_data/PetFinder-BreedLabels.csv\")\n",
        "petfinder_meta = \"/content/petfinder_data/train_metadata\"\n",
        "petfinder_images = \"/content/petfinder_data/train_images\"\n",
        "\n",
        "def extract_petfinder():\n",
        "    data = []\n",
        "    for file in tqdm(os.listdir(petfinder_meta)):\n",
        "        with open(os.path.join(petfinder_meta, file)) as f:\n",
        "            meta = json.load(f)\n",
        "        pet_id = file.replace('.json', '')\n",
        "        breed_id = meta.get(\"Breed1\")\n",
        "        breed_match = breed_labels[breed_labels[\"BreedID\"] == breed_id]\n",
        "        if breed_match.empty:\n",
        "            continue\n",
        "        breed = breed_match[\"BreedName\"].values[0]\n",
        "        img_path = os.path.join(petfinder_images, f\"{pet_id}-1.jpg\")\n",
        "        if os.path.exists(img_path):\n",
        "            data.append((img_path, breed.lower().strip()))\n",
        "    return data\n",
        "\n",
        "def extract_oxford():\n",
        "    anno_path = \"/content/oxford_pet_data/annotations/list.txt\"\n",
        "    anno_df = pd.read_csv(anno_path, skiprows=6, sep=\" \", header=None)\n",
        "    anno_df.columns = [\"file\", \"class_id\", \"species\", \"breed_id\"]\n",
        "    data = []\n",
        "    for _, row in anno_df.iterrows():\n",
        "        img_path = f\"/content/oxford_pet_data/images/{row['file']}.jpg\"\n",
        "        if os.path.exists(img_path):\n",
        "            breed = row[\"file\"].split(\"_\")[0]\n",
        "            data.append((img_path, breed.lower().strip()))\n",
        "    return data\n",
        "\n",
        "def extract_stanford():\n",
        "    root = \"/content/stanford_dogs/Images\"\n",
        "    data = []\n",
        "    for breed_dir in os.listdir(root):\n",
        "        breed_name = breed_dir.split(\"-\")[-1].replace(\"_\", \" \").lower().strip()\n",
        "        for img_file in os.listdir(os.path.join(root, breed_dir)):\n",
        "            img_path = os.path.join(root, breed_dir, img_file)\n",
        "            data.append((img_path, breed_name))\n",
        "    return data\n",
        "\n",
        "petfinder_data = extract_petfinder()\n",
        "oxford_data = extract_oxford()\n",
        "stanford_data = extract_stanford()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adAFkmHC8FFP",
        "outputId": "fa5b1058-64e9-4348-d4aa-c6ef0d0e48c5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 58311/58311 [00:19<00:00, 3038.41it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_data = petfinder_data + stanford_data + oxford_data\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(combined_data, columns=[\"image_path\", \"breed_name\"])\n",
        "\n",
        "# Normalize breed names: lowercase and strip whitespace\n",
        "df[\"breed_name\"] = df[\"breed_name\"].str.lower().str.strip()\n",
        "\n",
        "# Drop duplicates\n",
        "df = df.drop_duplicates(subset=[\"image_path\", \"breed_name\"])\n",
        "\n",
        "# Count breed occurrences\n",
        "breed_counts = df[\"breed_name\"].value_counts()\n",
        "\n",
        "print(f\"‚úÖ Total images (raw): {len(df)}\")\n",
        "print(f\"‚úÖ Unique breeds (raw): {df['breed_name'].nunique()}\")\n",
        "print(\"üìä Sample breed counts:\\n\", breed_counts.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkX0RYkK8IIi",
        "outputId": "a06b6f63-22af-49b7-91a6-fe8cb5a03d2e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Total images (raw): 27929\n",
            "‚úÖ Unique breeds (raw): 145\n",
            "üìä Sample breed counts:\n",
            " breed_name\n",
            "pomeranian      419\n",
            "samoyed         418\n",
            "american        400\n",
            "pug             400\n",
            "english         396\n",
            "beagle          395\n",
            "newfoundland    391\n",
            "basset          375\n",
            "keeshond        357\n",
            "chihuahua       352\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image, ImageEnhance\n",
        "import random\n",
        "\n",
        "balanced_data = []\n",
        "\n",
        "def augment_image(image_path):\n",
        "    try:\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        operations = [\n",
        "            lambda x: x.rotate(random.randint(-15, 15)),\n",
        "            lambda x: ImageEnhance.Color(x).enhance(random.uniform(0.8, 1.2)),\n",
        "            lambda x: ImageEnhance.Brightness(x).enhance(random.uniform(0.7, 1.3)),\n",
        "            lambda x: ImageEnhance.Contrast(x).enhance(random.uniform(0.8, 1.2))\n",
        "        ]\n",
        "        op = random.choice(operations)\n",
        "        return op(image)\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "# Group by breed\n",
        "grouped = df.groupby('breed_name')\n",
        "\n",
        "for breed, group in grouped:\n",
        "    images = group['image_path'].tolist()\n",
        "    count = len(images)\n",
        "\n",
        "    if count >= 200:\n",
        "        # Downsample to 200\n",
        "        selected = random.sample(images, 200)\n",
        "        balanced_data.extend([(img, breed) for img in selected])\n",
        "\n",
        "    else:\n",
        "        # Use all existing images\n",
        "        balanced_data.extend([(img, breed) for img in images])\n",
        "        needed = 200 - count\n",
        "\n",
        "        for i in range(needed):\n",
        "            original = random.choice(images)\n",
        "            augmented = augment_image(original)\n",
        "            if augmented:\n",
        "                # Save augmented to a temporary path\n",
        "                aug_path = f\"/content/augmented/{breed}_{i}.jpg\"\n",
        "                os.makedirs(os.path.dirname(aug_path), exist_ok=True)\n",
        "                augmented.save(aug_path)\n",
        "                balanced_data.append((aug_path, breed))\n",
        "\n",
        "# Final DataFrame\n",
        "balanced_df = pd.DataFrame(balanced_data, columns=[\"image_path\", \"breed_name\"])\n",
        "\n",
        "# Check\n",
        "print(\"‚úÖ Final dataset size:\", len(balanced_df))\n",
        "print(\"‚úÖ Unique breeds:\", balanced_df[\"breed_name\"].nunique())\n",
        "print(\"‚úÖ Images per breed (should all be 200):\\n\")\n",
        "print(balanced_df['breed_name'].value_counts().head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBsV5Y3i8ltl",
        "outputId": "6297d946-a3b7-47aa-a853-a45ce778349e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Final dataset size: 29000\n",
            "‚úÖ Unique breeds: 145\n",
            "‚úÖ Images per breed (should all be 200):\n",
            "\n",
            "breed_name\n",
            "abyssinian             200\n",
            "affenpinscher          200\n",
            "afghan hound           200\n",
            "african hunting dog    200\n",
            "airedale               200\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pickle\n",
        "\n",
        "# Encode breed labels\n",
        "le = LabelEncoder()\n",
        "balanced_df[\"label\"] = le.fit_transform(balanced_df[\"breed_name\"])\n",
        "\n",
        "# Save encoder\n",
        "with open(\"/content/label_encoder.pkl\", \"wb\") as f:\n",
        "    pickle.dump(le, f)\n",
        "\n",
        "print(\"‚úÖ LabelEncoder saved at: /content/label_encoder.pkl\")\n",
        "print(\"‚úÖ Sample class labels:\\n\", list(le.classes_)[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1D367O4p8rXT",
        "outputId": "f4d78214-bb76-4971-b963-84ee513332ce"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ LabelEncoder saved at: /content/label_encoder.pkl\n",
            "‚úÖ Sample class labels:\n",
            " ['abyssinian', 'affenpinscher', 'afghan hound', 'african hunting dog', 'airedale', 'american', 'american staffordshire terrier', 'appenzeller', 'australian terrier', 'basenji']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Train/Test Split (80% train, 20% temp)\n",
        "train_df, temp_df = train_test_split(\n",
        "    balanced_df,\n",
        "    test_size=0.2,\n",
        "    stratify=balanced_df[\"breed_name\"],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Split temp into val/test (50/50 of remaining 20% = 10% each)\n",
        "val_df, test_df = train_test_split(\n",
        "    temp_df,\n",
        "    test_size=0.5,\n",
        "    stratify=temp_df[\"breed_name\"],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Split Sizes:\")\n",
        "print(f\"Train: {len(train_df)}\")\n",
        "print(f\"Val: {len(val_df)}\")\n",
        "print(f\"Test: {len(test_df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suBhU1xx8tuR",
        "outputId": "19a03e22-06a3-40d2-827f-0062badaad3c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Split Sizes:\n",
            "Train: 23200\n",
            "Val: 2900\n",
            "Test: 2900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Set output directory\n",
        "output_dir = \"/content/petify_data\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "def copy_images(df, subset):\n",
        "    for _, row in df.iterrows():\n",
        "        label = row[\"breed_name\"]\n",
        "        src = row[\"image_path\"]\n",
        "        dst_dir = os.path.join(output_dir, subset, label)\n",
        "        os.makedirs(dst_dir, exist_ok=True)\n",
        "        dst_path = os.path.join(dst_dir, os.path.basename(src))\n",
        "        try:\n",
        "            shutil.copy(src, dst_path)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Failed to copy {src}: {e}\")\n",
        "\n",
        "# Copy images to folders\n",
        "copy_images(train_df, \"train\")\n",
        "copy_images(val_df, \"val\")\n",
        "copy_images(test_df, \"test\")\n",
        "\n",
        "print(\"‚úÖ Image folders created under /content/petify_data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AZEyPoe8znO",
        "outputId": "56e80585-5437-482d-c15c-98e728041f67"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Image folders created under /content/petify_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "train_breeds = os.listdir(f\"{output_dir}/train\")\n",
        "print(f\"‚úÖ Total Breeds in Training Folder: {len(train_breeds)}\")\n",
        "\n",
        "# Check breed sample\n",
        "print(\"üìÇ Sample Breed Folders:\", train_breeds[:5])\n",
        "\n",
        "# Check number of images in one breed\n",
        "sample_breed = train_breeds[0]\n",
        "num_images = len(os.listdir(f\"{output_dir}/train/{sample_breed}\"))\n",
        "print(f\"‚úÖ Images in breed '{sample_breed}': {num_images}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XIkmr7Q9Yuz",
        "outputId": "0d715b6a-eeda-43bf-e81d-a99799f6df72"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Total Breeds in Training Folder: 145\n",
            "üìÇ Sample Breed Folders: ['eskimo dog', 'bedlington terrier', 'bernese mountain dog', 'miniature', 'basenji']\n",
            "‚úÖ Images in breed 'eskimo dog': 160\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: download tensorflow\n",
        "\n",
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dm03-cWd_5Nb",
        "outputId": "e56fe008-2c2c-4e68-db32-0dc140eaf319"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow)\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
            "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting libclang>=13.0.0 (from tensorflow)\n",
            "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
            "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.1)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
            "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.3.6)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard~=2.19.0->tensorflow)\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m644.9/644.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: libclang, flatbuffers, wheel, werkzeug, tensorflow-io-gcs-filesystem, tensorboard-data-server, google-pasta, tensorboard, astunparse, tensorflow\n",
            "Successfully installed astunparse-1.6.3 flatbuffers-25.2.10 google-pasta-0.2.0 libclang-18.1.1 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 tensorflow-io-gcs-filesystem-0.37.1 werkzeug-3.1.3 wheel-0.45.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Constants\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = (224, 224)\n",
        "DATA_DIR = \"/content/petify_data\"\n",
        "\n",
        "# Load datasets\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    os.path.join(DATA_DIR, \"train\"),\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    label_mode=\"categorical\"\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    os.path.join(DATA_DIR, \"val\"),\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    label_mode=\"categorical\"\n",
        ")\n",
        "\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    os.path.join(DATA_DIR, \"test\"),\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    label_mode=\"categorical\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXmk2dBG9ezk",
        "outputId": "8a8a3e63-e521-44fa-88da-e0e877110985"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 23200 files belonging to 145 classes.\n",
            "Found 2900 files belonging to 145 classes.\n",
            "Found 2900 files belonging to 145 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf # Ensure tf is imported\n",
        "\n",
        "# Helper function to convert tf.data.Dataset to numpy arrays\n",
        "def dataset_to_numpy(ds):\n",
        "    X = []\n",
        "    y = []\n",
        "    print(f\"Processing dataset with element spec: {ds.element_spec}\") # Print element spec for debugging\n",
        "    expected_flat_shape = None\n",
        "    for images, labels in ds:\n",
        "        # Process each image in the batch\n",
        "        for i in range(images.shape[0]):\n",
        "            try:\n",
        "                image = images[i]\n",
        "                label = labels[i]\n",
        "                flattened_image = image.numpy().flatten()  # flatten image\n",
        "\n",
        "                if expected_flat_shape is None:\n",
        "                    expected_flat_shape = flattened_image.shape[0]\n",
        "                    print(f\"Expected flattened image shape: {expected_flat_shape}\")\n",
        "\n",
        "                # Check if the flattened shape matches the expected shape\n",
        "                if flattened_image.shape[0] == expected_flat_shape:\n",
        "                    X.append(flattened_image)\n",
        "                    # convert one-hot to class index if label_mode was 'categorical'\n",
        "                    if label.shape.rank > 0:\n",
        "                         y.append(np.argmax(label.numpy()))\n",
        "                    else: # Handle scalar labels if label_mode was 'int'\n",
        "                         y.append(label.numpy())\n",
        "                else:\n",
        "                    print(f\"‚ö†Ô∏è Skipping image due to inconsistent shape. Expected {expected_flat_shape}, got {flattened_image.shape[0]}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è Error processing image in batch: {e}\")\n",
        "\n",
        "    # Convert lists to numpy arrays. Use dtype=object if necessary to handle potential shape differences that weren't caught\n",
        "    # This might indicate a more fundamental issue if it's still needed, but can help in debugging.\n",
        "    # np.array(X, dtype=object)\n",
        "    try:\n",
        "        X_array = np.array(X)\n",
        "        y_array = np.array(y)\n",
        "        return X_array, y_array\n",
        "    except ValueError as e:\n",
        "        print(f\"Fatal error creating numpy array: {e}\")\n",
        "        print(f\"Shape of collected X elements: {[item.shape for item in X]}\")\n",
        "        print(f\"Number of collected X elements: {len(X)}\")\n",
        "        raise e # Re-raise the error after printing debug info\n",
        "\n",
        "\n",
        "X_train, y_train = dataset_to_numpy(train_ds)\n",
        "X_val, y_val = dataset_to_numpy(val_ds)\n",
        "X_test, y_test = dataset_to_numpy(test_ds)\n",
        "\n",
        "print(\"‚úÖ Converted datasets to flat arrays.\")\n",
        "print(f\"Shape: X_train = {X_train.shape}, y_train = {y_train.shape}\")\n",
        "print(f\"Shape: X_val = {X_val.shape}, y_val = {y_val.shape}\")\n",
        "print(f\"Shape: X_test = {X_test.shape}, y_test = {y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIuFgNJE82ki",
        "outputId": "c505b93a-ca3e-4359-cf61-7bf77e8fc029"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing dataset with element spec: (TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 145), dtype=tf.float32, name=None))\n",
            "Expected flattened image shape: 150528\n",
            "Processing dataset with element spec: (TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 145), dtype=tf.float32, name=None))\n",
            "Expected flattened image shape: 150528\n",
            "Processing dataset with element spec: (TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 145), dtype=tf.float32, name=None))\n",
            "Expected flattened image shape: 150528\n",
            "‚úÖ Converted datasets to flat arrays.\n",
            "Shape: X_train = (23200, 150528), y_train = (23200,)\n",
            "Shape: X_val = (2900, 150528), y_val = (2900,)\n",
            "Shape: X_test = (2900, 150528), y_test = (2900,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Reduce to 500 features (tunable)\n",
        "pca = PCA(n_components=500)\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_val_pca = pca.transform(X_val)\n",
        "X_test_pca = pca.transform(X_test)\n"
      ],
      "metadata": {
        "id": "K3ufE6C89Bcg"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: install XGBoost\n",
        "\n",
        "!pip install xgboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyxC__iWLxP1",
        "outputId": "68e4cd4c-cacf-49b3-cbf8-63b848ed5785"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xgboost\n",
            "  Downloading xgboost-3.0.1-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.0.2)\n",
            "Collecting nvidia-nccl-cu12 (from xgboost)\n",
            "  Downloading nvidia_nccl_cu12-2.26.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.15.3)\n",
            "Downloading xgboost-3.0.1-py3-none-manylinux_2_28_x86_64.whl (253.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m253.9/253.9 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (318.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m318.1/318.1 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nccl-cu12, xgboost\n",
            "Successfully installed nvidia-nccl-cu12-2.26.5 xgboost-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define model\n",
        "xgb = XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=10,\n",
        "    learning_rate=0.1,\n",
        "    objective='multi:softprob',\n",
        "    num_class=len(le.classes_),  # number of classes = num breeds\n",
        "    eval_metric='mlogloss',\n",
        "    use_label_encoder=False\n",
        ")\n",
        "\n",
        "# Train\n",
        "xgb.fit(X_train_pca, y_train, eval_set=[(X_val_pca, y_val)], verbose=True)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = xgb.predict(X_test_pca)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"‚úÖ XGBoost Test Accuracy: {acc:.2%}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qSqxkHO9D50",
        "outputId": "ecf71990-90e5-4c02-8206-ebd95156b860"
      },
      "execution_count": 22,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [15:37:43] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-mlogloss:4.91390\n",
            "[1]\tvalidation_0-mlogloss:4.86186\n",
            "[2]\tvalidation_0-mlogloss:4.81361\n",
            "[3]\tvalidation_0-mlogloss:4.76795\n",
            "[4]\tvalidation_0-mlogloss:4.73020\n",
            "[5]\tvalidation_0-mlogloss:4.69216\n",
            "[6]\tvalidation_0-mlogloss:4.66002\n",
            "[7]\tvalidation_0-mlogloss:4.62769\n",
            "[8]\tvalidation_0-mlogloss:4.59747\n",
            "[9]\tvalidation_0-mlogloss:4.57073\n",
            "[10]\tvalidation_0-mlogloss:4.54190\n",
            "[11]\tvalidation_0-mlogloss:4.51709\n",
            "[12]\tvalidation_0-mlogloss:4.49502\n",
            "[13]\tvalidation_0-mlogloss:4.47315\n",
            "[14]\tvalidation_0-mlogloss:4.45160\n",
            "[15]\tvalidation_0-mlogloss:4.43265\n",
            "[16]\tvalidation_0-mlogloss:4.41466\n",
            "[17]\tvalidation_0-mlogloss:4.39722\n",
            "[18]\tvalidation_0-mlogloss:4.38249\n",
            "[19]\tvalidation_0-mlogloss:4.36660\n",
            "[20]\tvalidation_0-mlogloss:4.35238\n",
            "[21]\tvalidation_0-mlogloss:4.33937\n",
            "[22]\tvalidation_0-mlogloss:4.32679\n",
            "[23]\tvalidation_0-mlogloss:4.31452\n",
            "[24]\tvalidation_0-mlogloss:4.30280\n",
            "[25]\tvalidation_0-mlogloss:4.29277\n",
            "[26]\tvalidation_0-mlogloss:4.28232\n",
            "[27]\tvalidation_0-mlogloss:4.27228\n",
            "[28]\tvalidation_0-mlogloss:4.26306\n",
            "[29]\tvalidation_0-mlogloss:4.25426\n",
            "[30]\tvalidation_0-mlogloss:4.24671\n",
            "[31]\tvalidation_0-mlogloss:4.23913\n",
            "[32]\tvalidation_0-mlogloss:4.23112\n",
            "[33]\tvalidation_0-mlogloss:4.22370\n",
            "[34]\tvalidation_0-mlogloss:4.21624\n",
            "[35]\tvalidation_0-mlogloss:4.20947\n",
            "[36]\tvalidation_0-mlogloss:4.20190\n",
            "[37]\tvalidation_0-mlogloss:4.19589\n",
            "[38]\tvalidation_0-mlogloss:4.19053\n",
            "[39]\tvalidation_0-mlogloss:4.18436\n",
            "[40]\tvalidation_0-mlogloss:4.17952\n",
            "[41]\tvalidation_0-mlogloss:4.17371\n",
            "[42]\tvalidation_0-mlogloss:4.16878\n",
            "[43]\tvalidation_0-mlogloss:4.16316\n",
            "[44]\tvalidation_0-mlogloss:4.15863\n",
            "[45]\tvalidation_0-mlogloss:4.15422\n",
            "[46]\tvalidation_0-mlogloss:4.15007\n",
            "[47]\tvalidation_0-mlogloss:4.14574\n",
            "[48]\tvalidation_0-mlogloss:4.14237\n",
            "[49]\tvalidation_0-mlogloss:4.13783\n",
            "[50]\tvalidation_0-mlogloss:4.13417\n",
            "[51]\tvalidation_0-mlogloss:4.12983\n",
            "[52]\tvalidation_0-mlogloss:4.12624\n",
            "[53]\tvalidation_0-mlogloss:4.12329\n",
            "[54]\tvalidation_0-mlogloss:4.12065\n",
            "[55]\tvalidation_0-mlogloss:4.11799\n",
            "[56]\tvalidation_0-mlogloss:4.11514\n",
            "[57]\tvalidation_0-mlogloss:4.11240\n",
            "[58]\tvalidation_0-mlogloss:4.10951\n",
            "[59]\tvalidation_0-mlogloss:4.10676\n",
            "[60]\tvalidation_0-mlogloss:4.10491\n",
            "[61]\tvalidation_0-mlogloss:4.10269\n",
            "[62]\tvalidation_0-mlogloss:4.10018\n",
            "[63]\tvalidation_0-mlogloss:4.09792\n",
            "[64]\tvalidation_0-mlogloss:4.09600\n",
            "[65]\tvalidation_0-mlogloss:4.09417\n",
            "[66]\tvalidation_0-mlogloss:4.09300\n",
            "[67]\tvalidation_0-mlogloss:4.09037\n",
            "[68]\tvalidation_0-mlogloss:4.08871\n",
            "[69]\tvalidation_0-mlogloss:4.08571\n",
            "[70]\tvalidation_0-mlogloss:4.08390\n",
            "[71]\tvalidation_0-mlogloss:4.08246\n",
            "[72]\tvalidation_0-mlogloss:4.08127\n",
            "[73]\tvalidation_0-mlogloss:4.07992\n",
            "[74]\tvalidation_0-mlogloss:4.07836\n",
            "[75]\tvalidation_0-mlogloss:4.07628\n",
            "[76]\tvalidation_0-mlogloss:4.07524\n",
            "[77]\tvalidation_0-mlogloss:4.07382\n",
            "[78]\tvalidation_0-mlogloss:4.07287\n",
            "[79]\tvalidation_0-mlogloss:4.07199\n",
            "[80]\tvalidation_0-mlogloss:4.07064\n",
            "[81]\tvalidation_0-mlogloss:4.06978\n",
            "[82]\tvalidation_0-mlogloss:4.06813\n",
            "[83]\tvalidation_0-mlogloss:4.06685\n",
            "[84]\tvalidation_0-mlogloss:4.06587\n",
            "[85]\tvalidation_0-mlogloss:4.06506\n",
            "[86]\tvalidation_0-mlogloss:4.06340\n",
            "[87]\tvalidation_0-mlogloss:4.06256\n",
            "[88]\tvalidation_0-mlogloss:4.06169\n",
            "[89]\tvalidation_0-mlogloss:4.06033\n",
            "[90]\tvalidation_0-mlogloss:4.05965\n",
            "[91]\tvalidation_0-mlogloss:4.05801\n",
            "[92]\tvalidation_0-mlogloss:4.05688\n",
            "[93]\tvalidation_0-mlogloss:4.05593\n",
            "[94]\tvalidation_0-mlogloss:4.05514\n",
            "[95]\tvalidation_0-mlogloss:4.05398\n",
            "[96]\tvalidation_0-mlogloss:4.05267\n",
            "[97]\tvalidation_0-mlogloss:4.05152\n",
            "[98]\tvalidation_0-mlogloss:4.05058\n",
            "[99]\tvalidation_0-mlogloss:4.04937\n",
            "‚úÖ XGBoost Test Accuracy: 18.10%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKrDPk02Q2jf",
        "outputId": "e0d2130e-6866-46de-a350-3646ddf2852c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "joblib.dump(xgb, '/content/drive/MyDrive/xgboost_petbreed_model.pkl')\n",
        "joblib.dump(pca, '/content/drive/MyDrive/pca_transformer.pkl')\n",
        "joblib.dump(le, '/content/drive/MyDrive/label_encoder.pkl')\n",
        "\n",
        "print(\"‚úÖ Saved XGBoost model, PCA, and Label Encoder.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYaW3ZFX9F3f",
        "outputId": "a7eaa790-0564-472f-ed04-9ca30f41ff07"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚úÖ Saved XGBoost model, PCA, and Label Encoder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YtNpexbtGHjJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}